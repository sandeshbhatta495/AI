{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3d03f799-8bae-4961-bb9c-541eae6f5fab",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7e8ffe04-d481-4fdb-ad0f-ee2779c15b19",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Generate concentric circles dataset\n",
    "# Why: Perfect non-linear data where linear fails and RBF shines\n",
    "def generate_circles_data(n_samples=200, noise=0.1, random_seed=42):\n",
    "    np.random.seed(random_seed)\n",
    "    n_half = n_samples // 2\n",
    "    \n",
    "    # Inner circle (class -1)\n",
    "    radius_inner = np.random.uniform(0, 0.5, n_half)\n",
    "    angle_inner = np.random.uniform(0, 2 * np.pi, n_half)\n",
    "    X_inner = np.column_stack((radius_inner * np.cos(angle_inner),\n",
    "                               radius_inner * np.sin(angle_inner)))\n",
    "    y_inner = -np.ones(n_half)\n",
    "    \n",
    "    # Outer ring (class +1)\n",
    "    radius_outer = np.random.uniform(0.8, 1.2, n_half)\n",
    "    angle_outer = np.random.uniform(0, 2 * np.pi, n_half)\n",
    "    X_outer = np.column_stack((radius_outer * np.cos(angle_outer),\n",
    "                               radius_outer * np.sin(angle_outer)))\n",
    "    X_outer += noise * np.random.randn(n_half, 2)\n",
    "    y_outer = np.ones(n_half)\n",
    "    \n",
    "    X = np.vstack((X_inner, X_outer))\n",
    "    y = np.hstack((y_inner, y_outer))\n",
    "    return X, y\n",
    "\n",
    "X, y = generate_circles_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8e6b2cb-7bdf-42a6-9764-3a883d87c607",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2: Define kernel functions\n",
    "# Why: These implement the kernel trick without explicit mapping\n",
    "def linear_kernel(X1, X2):\n",
    "    return np.dot(X1, X2.T)\n",
    "\n",
    "def polynomial_kernel(X1, X2, degree=3, coef0=1):\n",
    "    return (np.dot(X1, X2.T) + coef0) ** degree\n",
    "\n",
    "def rbf_kernel(X1, X2, gamma=5.0):\n",
    "    sq_dists = np.sum(X1**2, axis=1)[:, np.newaxis] + \\\n",
    "               np.sum(X2**2, axis=1)[np.newaxis, :] - \\\n",
    "               2 * np.dot(X1, X2.T)\n",
    "    return np.exp(-gamma * sq_dists)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9214db04-f460-4d4b-832a-b4ee8d58b64d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 3: Generalized Simple SVM class (works with any kernel)\n",
    "# Why: Reuses dual optimization logic; only kernel changes\n",
    "class SimpleKernelSVM:\n",
    "    def __init__(self, kernel='rbf', C=10.0, gamma=5.0, degree=3, coef0=1, tol=1e-3, max_iter=500):\n",
    "        self.kernel_name = kernel\n",
    "        self.C = C\n",
    "        self.gamma = gamma\n",
    "        self.degree = degree\n",
    "        self.coef0 = coef0\n",
    "        self.tol = tol\n",
    "        self.max_iter = max_iter\n",
    "    \n",
    "    def _kernel(self, X1, X2):\n",
    "        if self.kernel_name == 'linear':\n",
    "            return linear_kernel(X1, X2)\n",
    "        elif self.kernel_name == 'poly':\n",
    "            return polynomial_kernel(X1, X2, self.degree, self.coef0)\n",
    "        elif self.kernel_name == 'rbf':\n",
    "            return rbf_kernel(X1, X2, self.gamma)\n",
    "    \n",
    "    def fit(self, X, y):\n",
    "        n = X.shape[0]\n",
    "        self.X = X\n",
    "        self.y = y\n",
    "        K = self._kernel(X, X)\n",
    "        \n",
    "        alphas = np.zeros(n)\n",
    "        \n",
    "        for _ in range(self.max_iter):\n",
    "            prev_alphas = alphas.copy()\n",
    "            for i in range(n):\n",
    "                f_i = np.sum(alphas * y * K[:, i])\n",
    "                if hasattr(self, 'b'):\n",
    "                    f_i += self.b\n",
    "                E_i = f_i - y[i]\n",
    "                \n",
    "                if (y[i] * E_i < -self.tol and alphas[i] < self.C) or \\\n",
    "                   (y[i] * E_i > self.tol and alphas[i] > 0):\n",
    "                    eta = K[i,i]\n",
    "                    if eta > 1e-8:\n",
    "                        delta = y[i] * E_i / eta\n",
    "                        alphas[i] = np.clip(alphas[i] - delta, 0, self.C)\n",
    "            \n",
    "            # Enforce zero-sum constraint\n",
    "            violation = np.dot(alphas, y)\n",
    "            if abs(violation) > 1e-5:\n",
    "                alphas -= violation * y / n\n",
    "                alphas = np.clip(alphas, 0, self.C)\n",
    "            \n",
    "            if np.linalg.norm(alphas - prev_alphas) < self.tol:\n",
    "                break\n",
    "        \n",
    "        sv = alphas > 1e-5\n",
    "        if np.any(sv):\n",
    "            self.b = np.mean(y[sv] - np.dot((alphas[sv] * y[sv]), K[sv][:, sv]))\n",
    "        else:\n",
    "            self.b = 0\n",
    "        \n",
    "        self.alphas = alphas\n",
    "        self.sv_idx = sv\n",
    "        self.support_vectors = X[sv]\n",
    "        self.sv_y = y[sv]\n",
    "        self.sv_alphas = alphas[sv]\n",
    "    \n",
    "    def decision_function(self, X_test):\n",
    "        K_test = self._kernel(X_test, self.support_vectors)\n",
    "        return np.dot(self.sv_alphas * self.sv_y, K_test.T) + self.b\n",
    "    \n",
    "    def predict(self, X_test):\n",
    "        return np.sign(self.decision_function(X_test))\n",
    "    \n",
    "    def accuracy(self, X_test, y_test):\n",
    "        return np.mean(self.predict(X_test) == y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5430e7d-cb8e-4212-986b-1cfb7557c6c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 4: Train three models with different kernels\n",
    "models = [\n",
    "    ('Linear', SimpleKernelSVM(kernel='linear', C=10.0)),\n",
    "    ('Polynomial (deg=3)', SimpleKernelSVM(kernel='poly', degree=3, C=10.0)),\n",
    "    ('RBF (Î³=5)', SimpleKernelSVM(kernel='rbf', gamma=5.0, C=10.0))\n",
    "]\n",
    "\n",
    "trained_models = []\n",
    "accuracies = []\n",
    "\n",
    "for name, svm in models:\n",
    "    svm.fit(X, y)\n",
    "    acc = svm.accuracy(X, y)\n",
    "    trained_models.append((name, svm))\n",
    "    accuracies.append(acc)\n",
    "    print(f\"{name} - Training Accuracy: {acc:.3f}, Support Vectors: {np.sum(svm.sv_idx)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f5803c2-c026-4939-a801-e182d780ccae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 5: Plot all decision boundaries in one figure (side-by-side)\n",
    "fig, axes = plt.subplots(1, 3, figsize=(18, 6))\n",
    "margin = 0.3\n",
    "xx, yy = np.meshgrid(np.linspace(X[:,0].min()-margin, X[:,0].max()+margin, 200),\n",
    "                     np.linspace(X[:,1].min()-margin, X[:,1].max()+margin, 200))\n",
    "grid = np.c_[xx.ravel(), yy.ravel()]\n",
    "\n",
    "for ax, (name, svm), acc in zip(axes, trained_models, accuracies):\n",
    "    Z = svm.decision_function(grid).reshape(xx.shape)\n",
    "    \n",
    "    # Background contour\n",
    "    ax.contourf(xx, yy, Z, levels=50, cmap='coolwarm', alpha=0.8)\n",
    "    # Decision boundary (black line at 0)\n",
    "    ax.contour(xx, yy, Z, levels=[0], colors='black', linewidths=2)\n",
    "    \n",
    "    # Data points\n",
    "    ax.scatter(X[y==-1,0], X[y==-1,1], c='blue', label='Class -1 (Inner)', edgecolor='k', s=30)\n",
    "    ax.scatter(X[y==1,0], X[y==1,1], c='red', label='Class +1 (Outer)', edgecolor='k', s=30)\n",
    "    \n",
    "    # Highlight support vectors\n",
    "    sv = svm.support_vectors\n",
    "    ax.scatter(sv[:,0], sv[:,1], s=120, facecolors='none', edgecolors='lime', linewidths=2, label='Support Vectors')\n",
    "    \n",
    "    ax.set_title(f\"{name}\\nAccuracy: {acc:.3f} | SVs: {len(sv)}\")\n",
    "    ax.axis('equal')\n",
    "    ax.legend(loc='upper right')\n",
    "\n",
    "plt.suptitle(\"Kernel Comparison: Only RBF Perfectly Separates the Circles\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
